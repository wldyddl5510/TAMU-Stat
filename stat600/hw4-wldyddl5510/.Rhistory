a
a = rnorm(1, -2)
lambda = 0.5
soft1(a, lambda) == soft2(a, lambda)
a = rnorm(1, 2)
a
lambda = 2.5
soft1(a, lambda) == soft2(a, lambda)
microbenchmark(
soft1(a, lambda),
soft2(a, lambda)
)
#### updating
X
#### updating
X[, -1]
beta = rnorm(p)
beta
beta[-1]
beta[-2]
beta[-3]
beta[-4]
X[ , -2]
X[, -1] %*% beta[-1]
X[, -1]
beta[-1]
sum(X[, -1] %*% beta[-1])
X[, -1] %*% beta[-1]
is.null(NULL)
!is.null(NULL)
beta
beta[which(beta > 0)]
beta[which(beta >= 0)]
sort(beta)
sort(beta, decreasing = FALSE)
sort(beta, decreasing = TRUE)
sort(beta[which(beta >= 0)], decreasing = TRUE)
sort(beta[which(beta >= 0)], decreasing = TRUE)
warnings()
warnings("as")
?warnings
?warning
#### updating
# inside for loop
X = matrix(rnorm(n * p), n , p)
Y = rnorm(n)
beta = rnorm(p)
a = crossprod(X[ , 1], Y - (X[ , -1] %*% beta[-1])) / n
a
#### updating
# inside for loop
X = matrix(rnorm(n * p), n , p)
Y = rnorm(n)
beta_t = rnorm(p)
a = crossprod(X[ , 1], Y - (X[ , -1] %*% beta_t[-1])) / n
a
# vectorization
XtXb = crossprod(X) %*% beta
Xty = crossprod(X, Y)
# vectorization
XtXb = crossprod(X) %*% beta
Xty = crossprod(X, Y)
first_col_times_excluded_term = XtXb[1] - (sum(Xtilde[1]^2) * beta[1])
a = (Xty[1] - first_col_times_excluded_term) / n
#### updating
# inside for loop
X = matrix(rnorm(n * p), n , p)
Y = rnorm(n)
beta_t = rnorm(p)
a = crossprod(X[ , 1], Y - (X[ , -1] %*% beta_t[-1])) / n
a1 = crossprod(X[ , 1], Y - (X[ , -1] %*% beta_t[-1])) / n
a1
# vectorization
XtXb = crossprod(X) %*% beta
Xty = crossprod(X, Y)
first_col_times_excluded_term = XtXb[1] - (sum(Xtilde[1]^2) * beta[1])
a2 = (Xty[1] - first_col_times_excluded_term) / n
a1
a2
Xty[1]
crossprod(X[, 1], Y)
(X[ , -1] %*% beta_t[-1])
first_col_times_excluded_term
t(X[ ,1]) %*% (X[ , -1] %*% beta_t[-1])
(sum(Xtilde[1]^2) * beta[1])
XtXb[1]
t(X[ ,1]) %*% (X[ , -1] %*% beta_t[-1])
sum(Xtilde[1]^2)
beta[1]
XtXb[1]
(X[ , -1] %*% beta_t[-1]))
X[ , -1] %*% beta_t[-1]))
X[ , -1] %*% beta_t[-1])
X[ , -1] %*% beta_t[-1]
t(X[, 1]) %*% X[ , -1] %*% beta_t[-1]
t(X[, 1]) %*% X[ , 1] %*% beta_t[1]
# vectorization
XtXb = crossprod(X) %*% beta
Xty = crossprod(X, Y)
first_col_times_excluded_term = XtXb[1] - (sum(X[1]^2) * beta[1])
a2 = (Xty[1] - first_col_times_excluded_term) / n
a1
a2
#### updating
# inside for loop
X = matrix(rnorm(n * p), n , p)
Y = rnorm(n)
beta_t = rnorm(p)
a1 = crossprod(X[ , 1], Y - (X[ , -1] %*% beta_t[-1])) / n
a1
# vectorization
XtXb = crossprod(X) %*% beta
Xty = crossprod(X, Y)
first_col_times_excluded_term = XtXb[1] - (sum(X[1]^2) * beta[1])
a2 = (Xty[1] - first_col_times_excluded_term) / n
a1
a2
t(X[ ,1]) %*% (X[ , -1] %*% beta_t[-1])
#### updating
# inside for loop
X = matrix(rnorm(n * p), n , p)
Y = rnorm(n)
beta_t = rnorm(p)
a1 = crossprod(X[ , 1], Y - (X[ , -1] %*% beta_t[-1])) / n
a1
# vectorization
XtXb = crossprod(X) %*% beta
Xty = crossprod(X, Y)
first_col_times_excluded_term = XtXb[1] - (sum(X[1]^2) * beta[1])
a2 = (Xty[1] - first_col_times_excluded_term) / n
a1
a2
t(X[, 1]) %*% X[ , 1] %*% beta_t[1]
t(X[, 1]) %*% X[ , 1] %*% beta_t[1]
t(X[, 1]) %*% X[ , 1] %*% beta_t[1] + X[ , -1] %*% beta_t[-1])
t(X[, 1]) %*% X[ , 1] %*% beta_t[1] + X[ , -1] %*% beta_t[-1]
t(X[, 1]) %*% X[ , 1] %*% beta_t[1] + t(X[,1]) %*% X[ , -1] %*% beta_t[-1]
t(X[, 1]) %*% X[ , 1] %*% beta_t[1]
t(X[,1]) %*% X[ , -1] %*% beta_t[-1]
t(X) %*% X %*% beta
crossprod(X) %*% b
#### updating
# inside for loop
X = matrix(rnorm(n * p), n , p)
Y = rnorm(n)
beta_t = rnorm(p)
a1 = crossprod(X[ , 1], Y - (X[ , -1] %*% beta_t[-1])) / n
a1
# vectorization
XtXb = crossprod(X) %*% beta_t
Xty = crossprod(X, Y)
first_col_times_excluded_term = XtXb[1] - (sum(X[1]^2) * beta_t[1])
a2 = (Xty[1] - first_col_times_excluded_term) / n
a1
a2
t(X[ ,1]) %*% (X[ , -1] %*% beta_t[-1])
first_col_times_excluded_term
t(X[, 1]) %*% X[ , 1] %*% beta_t[1] + t(X[,1]) %*% X[ , -1] %*% beta_t[-1]
t(X[, 1]) %*% X[ , 1] %*% beta_t[1]
(sum(X[1]^2) * beta_t[1])
XtXb[1]
(sum(X[1]^2) * beta_t[1])
first_col_times_excluded_term = XtXb[1] - (crossprod(X[1]) * beta_t[1])
a2 = (Xty[1] - first_col_times_excluded_term) / n
a2
a1
crossprod(X[1]) * beta_t[1]
sum(X[1]^2) * beta_t[1]
t(X[, 1]) %*% X[ , 1] %*% beta_t[1]
first_col_times_excluded_term = XtXb[1] - (sum(X[ , 1]^2) * beta_t[1])
a2 = (Xty[1] - first_col_times_excluded_term) / n
a1
a2
#### updating
# inside for loop
X = matrix(rnorm(n * p), n , p)
Y = rnorm(n)
###### debugging and testing
# basic dataset
n = 3
p = 4
#### updating
# inside for loop
X = matrix(rnorm(n * p), n , p)
Y = rnorm(n)
beta_t = rnorm(p)
a1 = crossprod(X[ , 1], Y - (X[ , -1] %*% beta_t[-1])) / n
# vectorization
XtXb = crossprod(X) %*% beta_t
Xty = crossprod(X, Y)
first_col_times_excluded_term = XtXb[1] - (sum(X[ , 1]^2) * beta_t[1])
first_col_times_excluded_term = XtXb[1] - (crossprod(X[1]) * beta_t[1])
a2 = (Xty[1] - first_col_times_excluded_term) / n
a1
a2
first_col_times_excluded_term = XtXb[1] - (sum(X[ , 1]^2) * beta_t[1])
a2 = (Xty[1] - first_col_times_excluded_term) / n
a1
a2
col_calcul_mine <- function(X, Y, beta) {
XtXb = crossprod(X) %*% beta
Xty = crossprod(X, Y)
for(j in 1:ncol(X)) {
j_col_times_excluded_term = XtXb[j] - (sum(X[ , j]^2) * beta_t[j])
a = (Xty[j] - j_col_times_excluded_term) / n
}
}
#### compare speed with partial residual
col_calcul_lec <- function(X, Y, beta) {
r = Y - X %*% beta
a =
for(j in 1:ncol(X)) {
a = beta[j] + crossprod(X[ , j], r)
r = r + X[ , j] * (a - beta[j])
}
}
library(microbenchmark)
X = matrix(rnorm(400 * 2000), 400, 2000)
Y = rnorm(400)
beta = rnorn(2000)
beta = rnorn(2000)
beta = rnorm(2000)
microbenchmark(
col_calcul_lec(X, Y, beta),
col_calcul_mine(X, Y, beta)
)
warnings()
beta[j]
beta[1]
a = beta[1] + crossprod(X[ , 1], r)
r = Y - X %*% beta
r
a = beta[j] + crossprod(X[ , j], r)
a = beta[1] + crossprod(X[ , 1], r)
a
r = r + X[ , j] * (a - beta[j])
r = r + X[ , 1] * (a - beta[1])
X[ , 1] * (a - beta[1])
X[ , 1] * (a - beta[1])
X[ , 1] * (a - beta[1])
(a - beta[1])
a
X[ , 1] * as.nueric(a - beta[1])
r = r + X[ , 1] * as.numeric(a - beta[1])
r
X[ , 1] * as.nueric(a - beta[1])
r = r + X[ , 1] * (as.numeric(a) - beta[1])
r
r = r + X[ , 1] * (as.numeric(a) - beta[1])
a
r = r + X[ , 1] * (as.numeric(a) - beta[1])
n1 = 100
p1 = 2000
n_lambda1 = 30
k1 = 5
eps1 = 0.001
# data
X1 = matrix(rnorm(n1 * p1), n1, p1)
Y1 = rnorm(n1)
# 1. without lambda_seq, fold
res = cvLASSO(X1 ,Y1, lambda_seq = NULL, n_lambda1, k1, fold_ids = NULL, eps1)
# Y2 = rnorm(n1)
# load lib
source("LassoFunctions.R")
# 1. without lambda_seq, fold
res = cvLASSO(X1 ,Y1, lambda_seq = NULL, n_lambda1, k1, fold_ids = NULL, eps1)
res
# 2. properly stop at errors
# 2-1. n mismatch
cvLASSO(rbind(X1, rep(0, p1)), Y1, NULL, n_lambda1, k1, NULL, eps1)
# each function
# 1. standardize
standardized_res = standardizeXY(X1, Y1)
((colSums(standardized_res$Xtilde^2)/n1)[2])
as.numeric(crossprod(standardized_res[[1]])/n1)
colSums((scale(X1) * sqrt(n1/(n1-1))))/n1
(colSums(standardized_res$Xtilde^2)/n1)
colSums((scale(X1) * sqrt(n1/(n1-1))))/n1
colSums((scale(X1) * sqrt(n1/(n1-1)))^2)/n1
colSums((scale(X1) * sqrt(n1/(n1-1)))^2)/n1
((colSums(standardized_res$Xtilde^2)/n1))
colSums((scale(X1) * sqrt(n1/(n1-1)))^2)/n1 == ((colSums(standardized_res$Xtilde^2)/n1))
((colSums(standardized_res$Xtilde^2)/n1))
colSums((scale(X1) * sqrt(n1/(n1-1)))^2)/n1
dim(colSums((scale(X1) * sqrt(n1/(n1-1)))^2)/n1) == ((colSums(standardized_res$Xtilde^2)/n1))
dim(colSums((scale(X1) * sqrt(n1/(n1-1)))^2)/n1)
sum(colSums((scale(X1) * sqrt(n1/(n1-1)))^2)/n1 - ((colSums(standardized_res$Xtilde^2)/n1)))
(scale(Y1, scale = FALSE))[1]
sum((colSums((scale(X1) * sqrt(n1/(n1-1)))^2)/n1 - ((colSums(standardized_res$Xtilde^2)/n1)))^2)
(scale(Y1, scale = FALSE))[1]
standardized_res[[2]][1]
standardized_res$weights
# 2. soft
soft(1.3, 0.3)
soft(-1.3, 0.3)
soft(0.1, 0.3)
soft(-0.2, 0.3)
# 3. lasso
lasso(standardized_res$Xtilde, standardized_res$Ytilde, rep(1, p1), 1)
# 4. fitLASSOstandardized
ans = fitLASSOstandardized(standardized_res$Xtilde, standardized_res$Ytilde, 0.01, eps = eps1)
ans$fmin
ans$beta
fitLASSOstandardized(standardized_res$Xtilde, standardized_res$Ytilde, 0, eps = 0.00001)
# 5. fitLASSOstandardized_seq
fitlasso_std_res = fitLASSOstandardized_seq(standardized_res$Xtilde, standardized_res$Ytilde, NULL, n_lambda = n_lambda1, eps = eps1)
# 6. fitLASSO
fitlasso_res = fitLASSO(X1, Y1, NULL, n_lambda = n_lambda1, eps = eps1)
all(fitlasso_res$beta_mat == (fitlasso_std_res$beta_mat/standardized_res$weights))
fitlasso_res$beta0_vec
neg_lam_seq = c(-1, 0.02, -3)
fitLASSO(X1, Y1, neg_lam_seq, n_lambda = n_lambda1, eps = eps1)
# plot
colSums(fitlasso_res$beta_mat != 0)
plot(fitlasso_res$lambda_seq, colSums(fitlasso_res$beta_mat != 0))
fitLASSO(X1, Y1, neg_lam_seq, n_lambda = n_lambda1, eps = eps1)
neg_lam_seq = c(-1, -0.02, -3)
fitLASSO(X1, Y1, neg_lam_seq, n_lambda = n_lambda1, eps = eps1)
neg_lam_seq = c(-1, 0.02, -3)
fitLASSO(X1, Y1, neg_lam_seq, n_lambda = n_lambda1, eps = eps1)
neg_lam_seq = c(-1, 0.02, 3)
fitLASSO(X1, Y1, neg_lam_seq, n_lambda = n_lambda1, eps = eps1)
# data
X1 = matrix(rnorm(n1 * p1), n1, p1)
Y1 = rnorm(n1)
# Y2 = rnorm(n1)
# load lib
source("LassoFunctions.R")
n1 = 100
p1 = 2000
n_lambda1 = 30
k1 = 5
eps1 = 0.001
# data
X1 = matrix(rnorm(n1 * p1), n1, p1)
Y1 = rnorm(n1)
# Y2 = rnorm(n1)
# load lib
source("LassoFunctions.R")
# 1. without lambda_seq, fold
res = cvLASSO(X1 ,Y1, lambda_seq = NULL, n_lambda1, k1, fold_ids = NULL, eps1)
res
# 4. fitLASSOstandardized
ans = fitLASSOstandardized(standardized_res$Xtilde, standardized_res$Ytilde, 0.01, eps = eps1)
# each function
# 1. standardize
standardized_res = standardizeXY(X1, Y1)
((colSums(standardized_res$Xtilde^2)/n1))
as.numeric(crossprod(standardized_res[[1]])/n1)
sum((colSums((scale(X1) * sqrt(n1/(n1-1)))^2)/n1 - ((colSums(standardized_res$Xtilde^2)/n1)))^2)
standardized_res[[1]]
(scale(Y1, scale = FALSE))[1]
standardized_res[[2]][1]
standardized_res$weights
# 2. soft
soft(1.3, 0.3)
soft(-1.3, 0.3)
soft(0.1, 0.3)
soft(-0.2, 0.3)
# 3. lasso
lasso(standardized_res$Xtilde, standardized_res$Ytilde, rep(1, p1), 1)
# 4. fitLASSOstandardized
ans = fitLASSOstandardized(standardized_res$Xtilde, standardized_res$Ytilde, 0.01, eps = eps1)
ans$fmin
ans$beta
fitLASSOstandardized(standardized_res$Xtilde, standardized_res$Ytilde, 0, eps = 0.00001)
# 5. fitLASSOstandardized_seq
fitlasso_std_res = fitLASSOstandardized_seq(standardized_res$Xtilde, standardized_res$Ytilde, NULL, n_lambda = n_lambda1, eps = eps1)
# 6. fitLASSO
fitlasso_res = fitLASSO(X1, Y1, NULL, n_lambda = n_lambda1, eps = eps1)
all(fitlasso_res$beta_mat == (fitlasso_std_res$beta_mat/standardized_res$weights))
fitlasso_res$beta0_vec
neg_lam_seq = c(-1, 0.02, 3)
fitLASSO(X1, Y1, neg_lam_seq, n_lambda = n_lambda1, eps = eps1)
# Load the riboflavin data
# Uncomment below to install hdi package if you don't have it already;
# install.packages("hdi")
library(hdi)
data(riboflavin) # this puts list with name riboflavin into the R environment, y - outcome, x - gene expression
dim(riboflavin$x) # n = 71 samples by p = 4088 predictors
?riboflavin # this gives you more information on the dataset
# This is to make sure riboflavin$x can be converted and treated as matrix for faster computations
class(riboflavin$x) <- class(riboflavin$x)[-match("AsIs", class(riboflavin$x))]
# Get matrix X and response vector Y
X = as.matrix(riboflavin$x)
Y = riboflavin$y
# Source your lasso functions
source("LassoFunctions.R")
set.seed(1)
# [ToDo] Use your fitLASSO function on the riboflavin data with 60 tuning parameters
rib_fitlasso = fitLASSO(X, Y, NULL, n_lambda = 60)
# [ToDo] Based on the above output, plot the number of non-zero elements in each beta versus the value of tuning parameter
num_of_nonzero = colSums(rib_fitlasso$beta_mat != 0)
plot(rib_fitlasso$lambda_seq, num_of_nonzero)
# [ToDo] Use microbenchmark 10 times to check the timing of your fitLASSO function above with 60 tuning parameters
library(microbenchmark)
microbenchmark(
fitLASSO(X, Y, NULL, n_lambda = 60),
times = 10
)
# [ToDo] Report your median timing in the comments here: (~5.8 sec for Irina on her laptop)
# Unit: seconds
# expr      min       lq     mean   median       uq      max
# 2.959695 3.114957 3.634137 3.393925 3.495275 6.587223
# neval
# 10
# [ToDo] Use cvLASSO function on the riboflavin data with 30 tuning parameters (just 30 to make it faster)
rib_cvlasso = cvLASSO(X, Y, NULL, 30)
rib_cvlasso
# [ToDo] Based on the above output, plot the value of CV(lambda) versus tuning parameter. Note that this will change with each run since the folds are random, this is ok.
plot(rib_cvlasso$lambda_seq, rib_cvlasso$cvm, col = "red", ylim = c(0,1))
lines(rib_cvlasso$lambda_seq, rib_cvlasso$cvm + rib_cvlasso$cvse)
lines(rib_cvlasso$lambda_seq, rib_cvlasso$cvm - rib_cvlasso$cvse)
rib_cvlasso$lambda_min
rib_cvlasso$lambda_1se
#### testing
# parameters
set.seed(1)
n1 = 100
p1 = 2000
n_lambda1 = 30
k1 = 5
eps1 = 0.001
# data
X1 = matrix(rnorm(n1 * p1), n1, p1)
Y1 = rnorm(n1)
neg_lam_seq = c(-1, 0.02, 3)
fitLASSO(X1, Y1, neg_lam_seq, n_lambda = n_lambda1, eps = eps1)
#### testing
# parameters
set.seed(1)
n1 = 100
p1 = 2000
n_lambda1 = 30
k1 = 5
eps1 = 0.001
# data
X1 = matrix(rnorm(n1 * p1), n1, p1)
Y1 = rnorm(n1)
# Y2 = rnorm(n1)
# load lib
source("LassoFunctions.R")
# 1. without lambda_seq, fold
res = cvLASSO(X1 ,Y1, lambda_seq = NULL, n_lambda1, k1, fold_ids = NULL, eps1)
# 6. fitLASSO
fitlasso_res = fitLASSO(X1, Y1, NULL, n_lambda = n_lambda1, eps = eps1)
all(fitlasso_res$beta_mat == (fitlasso_std_res$beta_mat/standardized_res$weights))
fitlasso_res$beta0_vec
neg_lam_seq = c(-1, 0.02, 3)
fitLASSO(X1, Y1, neg_lam_seq, n_lambda = n_lambda1, eps = eps1)
# Load the riboflavin data
# Uncomment below to install hdi package if you don't have it already;
# install.packages("hdi")
library(hdi)
data(riboflavin) # this puts list with name riboflavin into the R environment, y - outcome, x - gene expression
dim(riboflavin$x) # n = 71 samples by p = 4088 predictors
?riboflavin # this gives you more information on the dataset
# This is to make sure riboflavin$x can be converted and treated as matrix for faster computations
class(riboflavin$x) <- class(riboflavin$x)[-match("AsIs", class(riboflavin$x))]
# Get matrix X and response vector Y
X = as.matrix(riboflavin$x)
Y = riboflavin$y
# Source your lasso functions
source("LassoFunctions.R")
set.seed(1)
# [ToDo] Use your fitLASSO function on the riboflavin data with 60 tuning parameters
rib_fitlasso = fitLASSO(X, Y, NULL, n_lambda = 60)
# [ToDo] Based on the above output, plot the number of non-zero elements in each beta versus the value of tuning parameter
num_of_nonzero = colSums(rib_fitlasso$beta_mat != 0)
plot(rib_fitlasso$lambda_seq, num_of_nonzero)
# [ToDo] Use microbenchmark 10 times to check the timing of your fitLASSO function above with 60 tuning parameters
library(microbenchmark)
microbenchmark(
fitLASSO(X, Y, NULL, n_lambda = 60),
times = 10
)
# [ToDo] Report your median timing in the comments here: (~5.8 sec for Irina on her laptop)
# Unit: seconds
# expr      min       lq     mean   median       uq      max
# 2.959695 3.114957 3.634137 3.393925 3.495275 6.587223
# neval
# 10
# [ToDo] Use cvLASSO function on the riboflavin data with 30 tuning parameters (just 30 to make it faster)
rib_cvlasso = cvLASSO(X, Y, NULL, 30)
rib_cvlasso
# [ToDo] Based on the above output, plot the value of CV(lambda) versus tuning parameter. Note that this will change with each run since the folds are random, this is ok.
plot(rib_cvlasso$lambda_seq, rib_cvlasso$cvm, col = "red", ylim = c(0,1))
lines(rib_cvlasso$lambda_seq, rib_cvlasso$cvm + rib_cvlasso$cvse)
lines(rib_cvlasso$lambda_seq, rib_cvlasso$cvm - rib_cvlasso$cvse)
rib_cvlasso$lambda_min
rib_cvlasso$lambda_1se
rib_fitlasso
rib_cvlasso
set.seed(1)
# [ToDo] Use cvLASSO function on the riboflavin data with 30 tuning parameters (just 30 to make it faster)
rib_cvlasso = cvLASSO(X, Y, NULL, 30)
rib_cvlasso
install.packages(c("Rcpp", "RcppArmadillo"))
library(Crpp)
library(Rcpp)
cppFunction("bool isOddCpp(int num) {bool result = ((num %% 2) == 1); return result;}")
cppFunction("bool isOddCpp(int num) {bool result = ((num %% 2) == 1); return result;}")
cppFunction("bool isOddCpp(int num) {bool result = ((num %% 2) == 1); return result;}")
cppFunction("bool isOddCpp(int num) {bool result = ((num %% 2) == 1); return result;}")
path()
cppFunction("bool isOddCpp(int num) {bool result = ((num %% 2) == 1); return result;}")
cppFunction("bool isOddCpp(int num) {bool result = ((num %% 2) == 1); return result;}")
cppFunction("bool isOddCpp(int num) {bool result = ((num %% 2) == 1); return result;}")
cppFunction("bool isOddCpp(int num) {bool result = ((num % 2) == 1); return result;}")
isOddCpp(3)
isOddCpp(2)
install.packages("RcppArmadillo")
